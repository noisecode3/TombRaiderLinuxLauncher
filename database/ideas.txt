how to check for host main certificate
#### Bash ####
echo | openssl s_client -connect www.trle.net:443 -servername www.trle.net 2>/dev/null\
        | openssl x509 -fingerprint -noout -serial -text

#### Python ####
"""xxx"""
import ssl
import socket
from cryptography import x509
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes, serialization

def get_certificate(hostname, port=443):
    """xxx"""
    context = ssl.create_default_context()
    # Disable certificate verification for the first connection
    context.check_hostname = False
    context.verify_mode = ssl.CERT_NONE

    with socket.create_connection((hostname, port)) as sock:
        with context.wrap_socket(sock, server_hostname=hostname) as ssock:
            # Get certificate info
            cert_der = ssock.getpeercert(True)
            if cert_der:
                return x509.load_der_x509_certificate(cert_der, default_backend())
    return None

def get_sha256_fingerprint(cert):
    """xxx"""
    cert_der = cert.public_bytes(serialization.Encoding.DER)
    digest = hashes.Hash(hashes.SHA256(), backend=default_backend())
    digest.update(cert_der)
    return digest.finalize()

def get_serial_number_hex(cert):
    """xxx"""
    # Get the serial number in a byte format
    serial_number_bytes = cert.serial_number \
        .to_bytes((cert.serial_number.bit_length() + 7) // 8, 'big')
    # Format it as a hex string
    return ':'.join(f'{b:02X}' for b in serial_number_bytes)

def print_certificate_details(cert):
    """xxx"""
    fingerprint = get_sha256_fingerprint(cert)
    fingerprint_hex = ':'.join(f'{b:02X}' for b in fingerprint)
    serial_number_hex = get_serial_number_hex(cert)

    print(f"SHA-256 fingerprint: {fingerprint_hex}")
    print(f"Serial number: {serial_number_hex}")
    print(f"Subject: {cert.subject}")
    print(f"Issuer: {cert.issuer}")
    print()

certificate = get_certificate('trle.net')
print_certificate_details(certificate)

#### C++ ####
And this is how we can ask the server to just give the certificate right there in c++
This is how we should have done this from the start, this is the normal way...

#include <iostream>
#include <boost/asio.hpp>
#include <boost/asio/ssl.hpp>
#include <openssl/x509.h>
#include <openssl/pem.h>
#include <openssl/bio.h>

namespace ssl = boost::asio::ssl;
using boost::asio::ip::tcp;

void get_ssl_certificate(const std::string& host) {
    boost::asio::io_context io_context;

    // Create SSL context
    ssl::context ssl_context(ssl::context::sslv23);

    // Create a TCP socket
    tcp::resolver resolver(io_context);
    tcp::resolver::results_type endpoints = resolver.resolve(host, "https");

    // Create SSL stream using the socket and the SSL context
    ssl::stream<tcp::socket> stream(io_context, ssl_context);

    // Set SNI (Server Name Indication)
    SSL_set_tlsext_host_name(stream.native_handle(), host.c_str());

    // Connect the socket to the resolved endpoint
    boost::asio::connect(stream.lowest_layer(), endpoints);

    // Perform SSL handshake
    stream.handshake(ssl::stream_base::client);

    // Retrieve and display the SSL certificate
    X509* cert = SSL_get_peer_certificate(stream.native_handle());
    if (cert) {
        std::cout << "SSL Certificate retrieved successfully!" << std::endl;

        // Convert X509* certificate to string using BIO
        BIO* bio = BIO_new(BIO_s_mem());
        PEM_write_bio_X509(bio, cert);

        char* cert_str = nullptr;
        long cert_len = BIO_get_mem_data(bio, &cert_str);

        // Print the certificate as a string
        std::cout << std::string(cert_str, cert_len) << std::endl;

        // Clean up
        BIO_free(bio);
        X509_free(cert);
    } else {
        std::cout << "No certificate found." << std::endl;
    }
}

int main() {
    std::string host = "www.trle.net";
    get_ssl_certificate(host);
    return 0;
}

### C++ ###
here we download an image with curl should be strait forward be we document it
#include <iostream>
#include <curl/curl.h>
#include <fstream>

size_t WriteCallback(void* contents, size_t size, size_t nmemb, void* userp) {
    std::ofstream* out = static_cast<std::ofstream*>(userp);
    size_t totalSize = size * nmemb;
    out->write(static_cast<char*>(contents), totalSize);
    return totalSize;
}

int main() {
    CURL* curl;
    CURLcode res;
    std::ofstream outFile("downloaded_image.jpg", std::ios::binary);

    if (!outFile) {
        std::cerr << "Failed to open file for writing." << std::endl;
        return 1;
    }

    curl = curl_easy_init();
    if (curl) {
        // Set the URL
        curl_easy_setopt(curl, CURLOPT_URL, "https://data.trcustoms.org/media/level_images/f5b2217a-28b6-4139-a285-174c83efc2c2.png");
        // Set the write function
        curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
        // Pass the output file stream to the callback function
        curl_easy_setopt(curl, CURLOPT_WRITEDATA, &outFile);
        // Perform the request
        res = curl_easy_perform(curl);
        // Check for errors
        if (res != CURLE_OK) {
            std::cerr << "curl_easy_perform() failed: " << curl_easy_strerror(res) << std::endl;
        }
        // Cleanup
        curl_easy_cleanup(curl);
    } else {
        std::cerr << "Failed to initialize CURL." << std::endl;
    }

    outFile.close();
    return 0;
}
### Python ###
this could help downloadin it to a file instead of using memory with nested functions
not sure I have understod this, kind of.

write_callback
 ├── Takes: file_obj
 └── Returns: _write (which has access to file_obj due to closure)
       └── Uses file_obj.write(data) within the PycURL callback context


class Downloader:
    def __init__(self):
        self.progress_bar = None

    def write_callback(self, file_obj):
        """Callback function to write data directly to a file."""
        def _write(data):
            file_obj.write(data)
            return len(data)
        return _write

    def download_file(self, url, save_path):
        curl = pycurl.Curl()
        curl.setopt(pycurl.URL, url)

        try:
            # Get file size for the progress bar
            curl.setopt(pycurl.NOBODY, True)
            curl.perform()
            total_size = curl.getinfo(pycurl.CONTENT_LENGTH_DOWNLOAD)
            curl.setopt(pycurl.NOBODY, False)

            # Open file for writing
            with open(save_path, 'wb') as f:
                # Set up the progress bar
                self.progress_bar = tqdm(total=total_size, unit='B', unit_scale=True)

                # Use write callback to stream directly to file
                curl.setopt(pycurl.WRITEFUNCTION, self.write_callback(f))
                curl.setopt(pycurl.FOLLOWLOCATION, True)
                curl.setopt(pycurl.NOPROGRESS, False)
                curl.setopt(pycurl.XFERINFOFUNCTION, self.progress_callback)

                # Perform the download
                curl.perform()

                # Retrieve the final URL after redirects
                final_url = curl.getinfo(pycurl.EFFECTIVE_URL)
                print(f"Final URL: {final_url}")

                # Extract the filename from the URL if present
                filename = final_url.split('/')[-1]
                print(f"Extracted Filename: {filename}")

        except pycurl.error as e:
            print(f"Download failed: {e}")

        finally:
            if self.progress_bar:
                self.progress_bar.close()
            curl.close()


Never forget how we can test one function in python:
python3 -c "from index_scrape import get_trle_page; print(get_trle_page(0, True))"


Tracking TRLE Records Efficiently

For TRCustoms, tracking and indexing records is streamlined and fast through JSON.

However, tracking records on TRLE is more complex. One approach could involve scanning
the latest pages and identifying any gaps in ID numbers. These gaps may indicate
deleted records, though it’s likely not necessary to handle them differently. However,
if a new record’s ID deviates significantly from the last known increment—for instance,
going from IDs 666, 667, and 668 to a much lower number like 345—then records
with these IDs should be checked for updates if they already exist in our database.

A full resync of TRLE data will be infrequent, as it would require around 3,700 requests,
potentially taking 1-2 days—something not feasible for regular users. To keep our
index database relevant and manageable, a yearly refresh should suffice. This approach
will focus on creating an index database of around 500 MB, rather than replicating
the entire TRLE database, which could exceed 20 GB. Additional data, such as levels
of specific interest to users, can be cached or downloaded manually, within a reasonable
limit of around 2 GB.

This was a special walkthrough the script cant handle
https://www.trle.net/sc/Levelwalk.php?lid=864
